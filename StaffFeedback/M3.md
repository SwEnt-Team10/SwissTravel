# SwEnt M3 Team Grading Report

This M3 milestone is the culmination of your SwEnt journey, and it gives us the final opportunity to give you, as a team, formal feedback on how you performed in the project. By now, you should be capable of demonstrating a solid command of the Scrum methodology and collaborative teamwork, and be able to deliver a high-quality application that is ready for real users.
This feedback report is meant to complement the informal, ungraded feedback that you received from your coaches during the weekly meetings, over email, on Discord, etc.

You can find the evaluation criteria in the [M3 Deliverables](https://github.com/swent-epfl/public/blob/main/project/M3.md) document.
As mentioned before, the standards for M2 were elevated relative to M1, and this progression continued into M3: we now hold you to the highest professional standard in SwEnt.

---

## Blue Belt

You qualified for a Blue Belt ðŸ¥‹ðŸ”µ and got a final team grade of 5.13/6 for M3. Excellent work! You're demonstrating advanced skills.

We looked at several aspects, grouped into seven categories for the team grade. Here is the breakdown of the points you earned:

| Metric                                   | **Points Earned**                | **Weight** | **Feedback**                               |
|------------------------------------------|----------------------------------|------------|--------------------------------------------|
| **Completeness**                         | 4.75 out of 6 | 20%        | [See Details](#completeness)               |
| **Functionality**                        | 4.9 out of 6 | 20%       | [See Details](#functionality)              |
| **User Experience**                      | 4.6 out of 6 | 5%       | [See Details](#user-experience)            |
| **Design and Maintainability**           | 5.55 out of 6 | 20% | [See Details](#design-and-maintainability) |
| **QA (Testing)**                         | 5.49 out of 6           | 20%        | [See Details](#qa-testing)                 |
| **Documentation**                        | 4.75 out of 6 | 10%       | [See Details](#documentation)              |
| **Autonomy**                             | 5.7 out of 6     | 5%         | [See Details](#autonomy)                   |
| **Final Team Grade**                     | **5.13 out of 6** |            |                                            |

In addition to the feedback you received from the coaches during the Sprints, you will find more detailed comments below.

---

## Completeness

We first evaluated the depth and complexity of the main epics in your app, along with their contribution to the app, the tangible value they provide to the user, and their alignment with the appâ€™s goals.

We evaluated the extent to which your app meets the course requirements articulated at the start of the semester, and whether they are implemented effectively, they integrate seamlessly, and are indeed essential to the app.

We also looked at the robustness and completeness of the different features you implemented: are all the features finished and polished, are they secure and bug-free, and are they thoughtfully designed.

The app covers the main functional requirements and presents a complete overall concept. The core epics are implemented with reasonable depth, and most major features are present and usable. The app demonstrates meaningful use of a public cloud service, integrates authentication correctly, and includes sensor usage that fits the applicationâ€™s idea.

Offline support exists, but transitions between offline and online states are unreliable, and caching is not used effectively. Users experience repeated loading and long wait times  (waited 10+ mins for profile to load, no result) instead of a smooth, resilient experience, which is particularly noticeable. 

While most features are implemented, several flows feel incomplete or fragile and do not fully handle edge cases. These gaps reduce the perceived polish and coherence expected at this stage. For example, if a user first clicks on an unavailabe trip, the enter an empty screen.

Overall, the product meets the core completeness criteria, but unresolved issues in offline handling, sensor impact, and feature robustness prevent it from feeling fully finished as a final deliverable.

For this part, you received 4.75/6.

---

## Functionality

In this context, we assessed your app's ability to handle unexpected inputs provided by clueless or malicious users (including spamming buttons, entering wrong inputs, stopping a process mid-way, etc.); we wanted to see that your app handles all edge cases gracefully, has comprehensive error handling, and includes robust mechanisms for maintaining stability under stress.

We then evaluated the performance and reliability of the final product, i.e., the APK: we wanted to see that your APK is stable and the UI responds quickly and has seamless navigation.

Next we looked into your implementation of user authentication and multi-user support: does the app correctly manage users, can users personalize their accounts, does the app support session persistence, are multi-user interactions well supported, can accounts be used on another device, and is account information preserved when switching devices.

The main flows work reliably in normal usage, and core interactions can be completed without major blockers. Data persistence is handled well, with information remaining consistent across sessions.

Where the app struggles is in handling edge cases and unexpected user actions. Interacting with unavailable content can lead to empty or broken states without clear feedback or recovery, requiring users to navigate back and retry. Improving error handling and making these situations more transparent to the user would noticeably strengthen the overall experience.

All required functional basics (account creation, login, and core collaboration features) are in place.

For this part, you received 4.9/6.

---

## User Experience

For this part, we wanted to see how intuitive and user-friendly the app is for real users. Beyond having good usability, did you pay attention to streamlining the interactions, is it easy to figure out, can new users start making good use of the app quickly, are the interaction flows well thought out and refined.

The app offers a rich set of features, but the overall experience can be confusing, especially in more complex flows such as the random trip generator. During use, it was often hard to understand what was happening and why.

Some parts of the app are difficult to follow, in particular the random trip generator. When generating a trip from Lausanne, several activities do not match their content: titles and descriptions refer to one place (e.g. Lavaux), while images and map locations are fixed to another (e.g. Lausanne Gare). This makes it unclear what the trip actually represents.

The trip path itself feels unclear, with locations jumping back and forth between cities. In addition, the swipe flow requires far too many decisions: in one session, this meant going through around 50 like/dislike actions, after which it was still unclear how to continue and required manual confirmation. This makes the flow tiring rather than engaging.

Finally, users have limited control over trips. If a user is added to a trip by a friend, there is no clear way to leave it, and even unfriending that person does not remove the trip. Making these actions clearer and reversible would improve the overall experience.

For this part, you received 4.6/6.

---

## Design and Maintainability

We evaluated whether your code is of high quality and employs best practices.
We expect the codebase to be polished, well documented, follow consistent conventions, be modular, and allow for easy modifications.
You should be able to employ advanced techniques by now, such as asynchronous functions (flows, coroutines), good resource management, and automated dependency injection (e.g., with Hilt).

We also assessed your overall app architecture and design, looking in particular at aspects surrounding robustness and scalability.
We looked at both the codebase and the documentation of the app (Wiki and architecture diagram), we expect your design to demonstrate thoughtful consideration for performance, maintainability, and future growth.

The architecture is pretty solid and should be scalable.

The repository is well orgamised and the code is clean and readable.

For this part, you received 5.55/6.

---

## QA (Testing)

The first aspect we looked at here was your test suite, in terms of both quality and the final line coverage.
We expect the testing to be rigorous and to cover all components and edge cases, and they should validate every significant user journey.
Your end-to-end tests should be detailed and include error-handling scenarios.
The tests should be well-documented and easy to maintain.
Finally, your test suite should demonstrate advanced techniques, mock data for performance testing, and automated regression tests.

The continuous integration pipeline runs on pull requests, ensuring that the project is automatically validated and that regressions are detected early.

Sonar is integrated into the repository, providing visibility into code quality issues and helping maintain a high standard of reliability.

For this part, you received 5.49/6.

---

## Documentation

We looked at your README and GitHub Wiki to evaluate the quality and completeness of your appâ€™s documentation. We expect the README and Wiki to be thorough and achieve professional-level clarity and completeness.
They should provide detailed descriptions of the app's architecture, implementation of the features, the development setup and guidelines for contributing.

We also assessed your use of Figma and the architecture diagram for effective UI design, organization, and app structure planning.
By this stage, we expect your Figma and Architecture diagram to be complete and up-to-date. The Figma should be consistent with the UI and the Architecture diagram should be comprehensive.

No additional developer-oriented documentation is provided. Supplementary materials such as CONTRIBUTING guidelines, module documentation, or API usage notes would help improve maintainability and ease onboarding for future contributors.

The architecture diagram could have been slightly improved by making it a bit clearer but other than this is is pretty complete.

The Figma is really complete and well organised and even contains an helpful prototype.

For this part, you received 4.75/6.

---

## Autonomy

A primary goal of SwEnt is to teach you how to function autonomously as a team.
For this part of the evaluation, we assessed you teamâ€™s independence, spanning Sprint 6 to Sprint 10, based on the meetings with coaches, Sprint planning, and how you managed risk.
By this stage, coaches should no longer be necessary for the team to operate, i.e., you can organize yourselves, you don't need to be reminded about tasks, and you can conduct the Scrum ceremonies on your own.

The team demonstrated autonomy during meetings, structuring discussions effectively and following the Scrum ceremony process without needing significant coach intervention.

The team maintained a respectful, constructive, and professional tone in meetings and discussions, contributing positively to collaboration and team cohesion.

For this part, you received 5.7/6.

---

## Summary

Based on the above points, your grade for this M3 milestone is 5.13/6. If you are interested in how this fits into the bigger grading scheme, please see [project README](https://github.com/swent-epfl/public/blob/main/project/README.md) and the [course README](https://github.com/swent-epfl/public/blob/main/README.md).

The entire SwEnt staff wishes you the very best in your career, and we look forward to seeing you do great things with what you learned this semester.
